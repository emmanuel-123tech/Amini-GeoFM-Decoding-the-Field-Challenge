{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12352713,"sourceType":"datasetVersion","datasetId":7787742}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# üåæ Crop Classification (No PRESTO) + Feature Engineering + Calibrated LightGBM\n# Google Colab-ready notebook ‚Äî No GeoFM, only smart time-series features\n\n# ‚úÖ STEP 1: Install required packages\n!pip install --quiet lightgbm==4.3.0 scipy\n\n# ‚úÖ STEP 2: Imports\nimport pandas as pd, numpy as np, lightgbm as lgb\nfrom scipy.stats import skew, kurtosis\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import log_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T22:21:38.470194Z","iopub.execute_input":"2025-07-19T22:21:38.470461Z","iopub.status.idle":"2025-07-19T22:21:47.048909Z","shell.execute_reply.started":"2025-07-19T22:21:38.470441Z","shell.execute_reply":"2025-07-19T22:21:47.048317Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# **CATBOOST + LGB**","metadata":{}},{"cell_type":"code","source":"# ================================================================\n#  Upgraded Rich Stats + Time NDVI + RedEdge Ratios + FFT Entropy\n# ================================================================\n!pip install -q catboost lightgbm==4.3.0\n\nimport pandas as pd, numpy as np, lightgbm as lgb, catboost as cb, gc\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import log_loss\nimport warnings, os\nwarnings.filterwarnings(\"ignore\")\n\n# ---------- Paths ----------\nTRAIN_CSV = '/kaggle/input/amini-geofm-decoding/dummy_satellite_data.csv'\nTEST_CSV  = '/kaggle/input/amini-geofm-decoding/test (24).csv'\n\ntrain_df = pd.read_csv(TRAIN_CSV)\ntest_df  = pd.read_csv(TEST_CSV)\n\n# ---------- Rename & add NDVI + RedEdge ratios ----------\nrename_bands = {\n    'blue':'B2','green':'B3','red':'B4',\n    'rededge1':'B5','rededge2':'B6','rededge3':'B7',\n    'nir':'B8','nir08':'B8A','swir16':'B11','swir22':'B12'\n}\ntrain_df, test_df = [df.rename(columns=rename_bands) for df in (train_df, test_df)]\n\nfor df in (train_df, test_df):\n    eps = 1e-6\n    df['time'] = pd.to_datetime(df['time'])\n    df['NDVI']      = (df['B8'] - df['B4']) / (df['B8'] + df['B4'] + eps)\n    df['RE1_ratio'] = df['B5'] / (df['B8'] + eps)\n    df['RE2_ratio'] = df['B6'] / (df['B8'] + eps)\n    df['RE_norm1']  = df['B6'] / (df['B5'] + eps)\n    df['RE_norm2']  = df['B7'] / (df['B5'] + eps)\n\nband_cols = ['B2','B3','B4','B5','B6','B7','B8','B8A','B11','B12',\n             'NDVI','RE1_ratio','RE2_ratio','RE_norm1','RE_norm2']\n\n# ---------- Feature engineering ----------\ndef basic_stats(v):\n    v = v[np.isfinite(v)]\n    if v.size == 0: return [0]*6\n    return [v.mean(), v.std(), v.min(), v.max(), np.percentile(v, 25), np.percentile(v, 75)]\n\ndef slope(v):\n    v = v[np.isfinite(v)]\n    if v.size < 2: return 0.\n    return float(LinearRegression().fit(np.arange(v.size).reshape(-1,1), v).coef_[0])\n\ndef fft_entropy(v):\n    v = v[np.isfinite(v)]\n    if v.size == 0: return 0.\n    f = np.fft.fft(v - v.mean())\n    power = np.abs(f)**2\n    prob = power / np.sum(power)\n    return float(-np.sum(prob * np.log(prob + 1e-12)))\n\ndef seasonal_ndvi_stats(df):\n    df = df.copy()\n    df['month'] = df['time'].dt.month\n    df['quarter'] = df['time'].dt.quarter\n    stats = []\n    for q in [1,2,3,4]:\n        vals = df[df['quarter']==q]['NDVI']\n        stats += [vals.mean() if not vals.empty else 0, vals.var() if not vals.empty else 0]\n    return stats\n\ndef pixel_feats(g):\n    f = []\n    for c in band_cols:\n        arr = g[c].values.astype('float64')\n        f += basic_stats(arr) + [slope(arr)]\n    f.append(fft_entropy(g['NDVI'].values))         # FFT entropy\n    f += seasonal_ndvi_stats(g)                     # NDVI seasonal stats\n    return np.array(f, dtype='float32')\n\ndef build_matrix(df):\n    rows, ids = [], []\n    for uid, g in df.groupby('unique_id'):\n        try:\n            rows.append(pixel_feats(g)); ids.append(uid)\n        except: continue\n    return pd.DataFrame(rows, index=ids)\n\nprint(\"üîÑ Building matrices ‚Ä¶\")\nX_train = build_matrix(train_df)\nX_test  = build_matrix(test_df)\n\ny_raw = train_df.groupby('unique_id')['crop_type'].first()\nle = LabelEncoder(); y = le.fit_transform(y_raw.loc[X_train.index])\n\n# ---------- 5-fold ----------\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\noof_lgb = np.zeros((len(X_train),3)); test_lgb = np.zeros((len(X_test),3))\noof_cat = np.zeros_like(oof_lgb);     test_cat = np.zeros_like(test_lgb)\n\n# ---------- LightGBM ----------\nlgb_param_sets = [\n    dict(num_leaves=64, learning_rate=0.03, max_depth=-1),\n    dict(num_leaves=32, learning_rate=0.06, max_depth=8),\n    dict(num_leaves=16, learning_rate=0.09, max_depth=6)\n]\nfor ps in lgb_param_sets:\n    pred_fold = np.zeros_like(test_lgb)\n    for tr, va in folds.split(X_train, y):\n        clf = lgb.LGBMClassifier(objective='multiclass', num_class=3,\n                                 n_estimators=19500, colsample_bytree=0.8, subsample=0.8,\n                                 min_data_in_leaf=20, reg_lambda=1.0, **ps)\n        clf.fit(X_train.iloc[tr], y[tr],\n                eval_set=[(X_train.iloc[va], y[va])],\n                eval_metric='multi_logloss',\n                callbacks=[lgb.early_stopping(300, verbose=False)])\n        oof_lgb[va] += clf.predict_proba(X_train.iloc[va]) * 0.5\n        pred_fold += clf.predict_proba(X_test) / folds.n_splits\n        del clf; gc.collect()\n    test_lgb += pred_fold / len(lgb_param_sets)\n\n# ---------- CatBoost ----------\ncat_params = dict(\n    loss_function='MultiClass', eval_metric='MultiClass',\n    learning_rate=0.06, depth=8, l2_leaf_reg=4,\n    iterations=16000, random_seed=42, verbose=False,\n    allow_writing_files=False\n)\ncat_params['task_type'] = 'GPU' if os.environ.get(\"CUDA_VISIBLE_DEVICES\") else 'CPU'\n\nfor tr, va in folds.split(X_train, y):\n    cb_train = cb.Pool(X_train.iloc[tr], label=y[tr])\n    cb_val   = cb.Pool(X_train.iloc[va], label=y[va])\n    model = cb.CatBoostClassifier(**cat_params)\n    model.fit(cb_train, eval_set=cb_val, early_stopping_rounds=250, verbose=False)\n    oof_cat[va] = model.predict_proba(cb_val)\n    test_cat += model.predict_proba(X_test) / folds.n_splits\n    del model; gc.collect()\n\n# ---------- Blending ----------\nlgb_log = log_loss(y, oof_lgb); cat_log = log_loss(y, oof_cat)\nw_lgb = 1 / cat_log; w_cat = 1 / lgb_log\nalpha = w_lgb / (w_lgb + w_cat)\nprint(f\"OOF LGB logloss {lgb_log:.4f}  |  CatBoost {cat_log:.4f}  ‚Üí Œ±={alpha:.2f}\")\n\nensemble_pred = alpha * test_lgb + (1 - alpha) * test_cat\n\n# ---------- Submission ----------\nsub = pd.DataFrame(ensemble_pred, columns=le.classes_, index=X_test.index).reset_index()\nsub.rename(columns={'index': 'unique_id'}, inplace=True)\nsub.to_csv('_ensemble_UPGRADED.csv', index=False)\nprint(\"‚úÖ _ensemble_UPGRADED.csv saved!\")\ndisplay(sub.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T22:21:47.050134Z","iopub.execute_input":"2025-07-19T22:21:47.050646Z","execution_failed":"2025-07-19T22:22:32.834Z"}},"outputs":[{"name":"stdout","text":"üîÑ Building matrices ‚Ä¶\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}